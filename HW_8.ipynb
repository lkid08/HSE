{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1bf6f873",
      "metadata": {
        "id": "1bf6f873"
      },
      "source": [
        "# Домашнее задание № 8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b4bd487",
      "metadata": {
        "id": "3b4bd487"
      },
      "source": [
        "## Задание 1 (4 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf4c4f87",
      "metadata": {
        "id": "bf4c4f87"
      },
      "source": [
        "Обучите 8 моделей для задачи классификации текста (датасет - lenta_40k ). А именно:  \n",
        "1) модель с 1 GRU слоем;   \n",
        "2) модель с 1 LSTM слоем    \n",
        "3) модель с 1 GRU и 1 LSTM слоем  \n",
        "4) модель с 1 BIGRU и 2 LSTM слоями  \n",
        "7) модель с 7 GRU слоями и 3 LSTM слоями  \n",
        "6) модель 1 BIGRU и 1 BILSTM слоями, причем так чтобы модели для forward и backward прохода отличались   \n",
        "7) модель, где последовательно идут слои: LSTM, GRU, BILSTM, BIGRU, GRU, LSTM  \n",
        "\n",
        "\n",
        "\n",
        "Параметр units и размер эмбединга можете задать любой. Оцените качество каждой модели и определите победителя."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "83db6635",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83db6635",
        "outputId": "230496e3-fa40-4c37-afd6-d7058bdde22f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /home/user/.venv/lib/python3.10/site-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /home/user/.venv/lib/python3.10/site-packages (1.3.2)\n",
            "Requirement already satisfied: matplotlib in /home/user/.venv/lib/python3.10/site-packages (3.8.3)\n",
            "Requirement already satisfied: tensorflow in /home/user/.venv/lib/python3.10/site-packages (2.15.0.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/user/.venv/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/user/.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/user/.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /home/user/.venv/lib/python3.10/site-packages (from pandas) (1.24.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /home/user/.venv/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/user/.venv/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/user/.venv/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/user/.venv/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/user/.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/user/.venv/lib/python3.10/site-packages (from matplotlib) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/user/.venv/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/user/.venv/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /home/user/.venv/lib/python3.10/site-packages (from matplotlib) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/user/.venv/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (4.25.3)\n",
            "Requirement already satisfied: setuptools in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (59.6.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /home/user/.venv/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/user/.venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/user/.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/user/.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/user/.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/user/.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/user/.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/user/.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/user/.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user/.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/user/.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/user/.venv/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/user/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/user/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/user/.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/user/.venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/user/.venv/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn matplotlib tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ArJ8UlFCOMNl",
      "metadata": {
        "id": "ArJ8UlFCOMNl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-22 11:34:46.794585: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-22 11:34:46.794676: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-22 11:34:46.799235: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-22 11:34:46.813412: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-02-22 11:34:47.834629: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "50362f6e",
      "metadata": {
        "id": "50362f6e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6ee34029",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "WzDdDz06OWs3",
      "metadata": {
        "id": "WzDdDz06OWs3"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/home/user/dolgov/hw/lenta_40k.csv.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "RH4ZHbQgOY08",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RH4ZHbQgOY08",
        "outputId": "9a07a8e2-1102-4e3a-ff9a-bf30faade258"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Россия должна сотрудничать с Всемирным антидоп...</td>\n",
              "      <td>Спорт</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Уголовный суд Кувейта 28 июня освободил под за...</td>\n",
              "      <td>Мир</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Французский журнал Charlie Hebdo опубликовал н...</td>\n",
              "      <td>Интернет и СМИ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>В Петербурге в доме № 53 по улице Лени Голиков...</td>\n",
              "      <td>Россия</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>В московском аэропорту \"Домодедово\" задержан г...</td>\n",
              "      <td>Россия</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text           topic\n",
              "0  Россия должна сотрудничать с Всемирным антидоп...           Спорт\n",
              "1  Уголовный суд Кувейта 28 июня освободил под за...             Мир\n",
              "2  Французский журнал Charlie Hebdo опубликовал н...  Интернет и СМИ\n",
              "3  В Петербурге в доме № 53 по улице Лени Голиков...          Россия\n",
              "4  В московском аэропорту \"Домодедово\" задержан г...          Россия"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b6676dab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6676dab",
        "outputId": "71f41fe6-eaa7-40e1-bfcd-8d0081b5dc0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Спорт', 'Мир', 'Интернет и СМИ', 'Россия', 'Наука и техника',\n",
              "       'Силовые структуры', 'Бывший СССР', 'Культура', 'Экономика',\n",
              "       'Ценности', 'Из жизни', 'Дом', 'Бизнес', '69-я параллель', 'Крым',\n",
              "       'Путешествия', 'Культпросвет ', 'Легпром', 'Библиотека'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.topic.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "oUlVs8LPz69E",
      "metadata": {
        "id": "oUlVs8LPz69E"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    tokens = text.lower().split()\n",
        "    tokens = [token.strip(punctuation) for token in tokens]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "m52qZBB60AhG",
      "metadata": {
        "id": "m52qZBB60AhG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6Wz75KSJ0Adl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wz75KSJ0Adl",
        "outputId": "840ba684-e656-4efa-dc15-21785aa78512"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "354611"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = Counter()\n",
        "\n",
        "for text in data.text:\n",
        "    vocab.update(preprocess(text))\n",
        "\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "PbDBMe3o0Kr6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbDBMe3o0Kr6",
        "outputId": "85ea4df3-fbc1-47f5-8b6c-eb6ad241df17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24091"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_vocab = set()\n",
        "\n",
        "for word in vocab:\n",
        "    if vocab[word] > 30:\n",
        "        filtered_vocab.add(word)\n",
        "\n",
        "\n",
        "len(filtered_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8fBvzFef0Ko7",
      "metadata": {
        "id": "8fBvzFef0Ko7"
      },
      "outputs": [],
      "source": [
        "word2id = {'PAD':0, 'UNK':1}\n",
        "\n",
        "for word in filtered_vocab:\n",
        "    word2id[word] = len(word2id)\n",
        "\n",
        "id2word = {i:word for word, i in word2id.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "QfAtNu-B0Ki7",
      "metadata": {
        "id": "QfAtNu-B0Ki7"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "\n",
        "for text in data.text:\n",
        "    tokens = preprocess(text)\n",
        "    ids = [word2id.get(token, 1) for token in tokens]\n",
        "    X.append(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3HgSFvuWz64r",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HgSFvuWz64r",
        "outputId": "e4b4e7b7-b9d1-4878-86df-126736daedbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1748, 170.0)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MAX_LEN = max(len(x) for x in X)\n",
        "\n",
        "MEAN_LEN = np.median([len(x) for x in X])\n",
        "MAX_LEN, MEAN_LEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "Pf5hcsuzz6yj",
      "metadata": {
        "id": "Pf5hcsuzz6yj"
      },
      "outputs": [],
      "source": [
        "# Увеличить размер эмбеддингов\n",
        "\n",
        "MAX_LEN = int(MEAN_LEN + 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "A8xTvCCiz6qm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8xTvCCiz6qm",
        "outputId": "a86445d7-9c94-4189-b5bc-4dab0d5e95d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(44356, 220)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_LEN)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "iEd8lesr0mIL",
      "metadata": {
        "id": "iEd8lesr0mIL"
      },
      "outputs": [],
      "source": [
        "id2label = {i:label for i, label in enumerate(set(data.topic.values))}\n",
        "label2id = {l:i for i, l in id2label.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "Y8zGT8V60mEt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8zGT8V60mEt",
        "outputId": "61ca9e48-523c-45f1-961d-7541d3d92bfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = tf.keras.utils.to_categorical([label2id[label] for label in data.topic.values])\n",
        "len(label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "HDlU11nv0mCl",
      "metadata": {
        "id": "HDlU11nv0mCl"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "qoU5sXA10mAY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoU5sXA10mAY",
        "outputId": "39091c4d-56d1-4780-d86e-f38031a46fdd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-22 11:35:00.708198: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-22 11:35:00.774642: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-22 11:35:00.775221: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-22 11:35:00.779654: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-22 11:35:00.780193: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-22 11:35:00.780680: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-22 11:35:01.138999: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-22 11:35:01.139544: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-22 11:35:01.140037: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-22 11:35:01.140462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 26385 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 220)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 220, 60)           1445580   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 90)                41040     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 19)                1729      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1488349 (5.68 MB)\n",
            "Trainable params: 1488349 (5.68 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 1) модель с 1 GRU слоем;\n",
        "\n",
        "inputs_1 = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings_1 = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=60)(inputs_1, )\n",
        "\n",
        "rnn_1 = tf.keras.layers.GRU(units=90, return_sequences=False)(embeddings_1)\n",
        "\n",
        "outputs_1 = tf.keras.layers.Dense(len(label2id), activation='softmax')(rnn_1)\n",
        "\n",
        "model_1 = tf.keras.Model(inputs=inputs_1, outputs=outputs_1)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_1.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1,\n",
        "                       tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5FOLiD3K1Hz_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FOLiD3K1Hz_",
        "outputId": "f99066d8-6bd9-43ec-c7ab-575721d6514a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-22 11:35:04.525351: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
            "2024-02-22 11:35:05.181530: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f2f8d212410 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2024-02-22 11:35:05.181570: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
            "2024-02-22 11:35:05.188714: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1708590905.317583  552971 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 11s 186ms/step - loss: 2.5630 - f1: 0.0000e+00 - rec@prec: 0.0000e+00 - val_loss: 2.3091 - val_f1: 0.0000e+00 - val_rec@prec: 4.5086e-04\n",
            "Epoch 2/20\n",
            "43/43 [==============================] - 7s 157ms/step - loss: 2.2408 - f1: 9.2653e-05 - rec@prec: 4.9836e-04 - val_loss: 2.1639 - val_f1: 0.0030 - val_rec@prec: 4.5086e-04\n",
            "Epoch 3/20\n",
            "43/43 [==============================] - 6s 149ms/step - loss: 2.0042 - f1: 0.0317 - rec@prec: 0.0060 - val_loss: 1.9169 - val_f1: 0.0932 - val_rec@prec: 0.0077\n",
            "Epoch 4/20\n",
            "43/43 [==============================] - 6s 138ms/step - loss: 1.7454 - f1: 0.1936 - rec@prec: 0.0662 - val_loss: 1.7952 - val_f1: 0.2225 - val_rec@prec: 0.0473\n",
            "Epoch 5/20\n",
            "43/43 [==============================] - 5s 105ms/step - loss: 1.5332 - f1: 0.3365 - rec@prec: 0.1730 - val_loss: 1.7237 - val_f1: 0.2626 - val_rec@prec: 0.0649\n",
            "Epoch 6/20\n",
            "43/43 [==============================] - 4s 104ms/step - loss: 1.3459 - f1: 0.4397 - rec@prec: 0.2874 - val_loss: 1.6599 - val_f1: 0.3533 - val_rec@prec: 0.1141\n",
            "Epoch 7/20\n",
            "43/43 [==============================] - 4s 85ms/step - loss: 1.1489 - f1: 0.5491 - rec@prec: 0.4244 - val_loss: 1.5782 - val_f1: 0.4512 - val_rec@prec: 0.1754\n",
            "Epoch 8/20\n",
            "43/43 [==============================] - 3s 71ms/step - loss: 0.9715 - f1: 0.6463 - rec@prec: 0.5601 - val_loss: 1.5977 - val_f1: 0.4725 - val_rec@prec: 0.2259\n",
            "Epoch 9/20\n",
            "43/43 [==============================] - 4s 104ms/step - loss: 0.8414 - f1: 0.7149 - rec@prec: 0.6822 - val_loss: 1.4342 - val_f1: 0.5691 - val_rec@prec: 0.2854\n",
            "Epoch 10/20\n",
            "43/43 [==============================] - 3s 75ms/step - loss: 0.6728 - f1: 0.7896 - rec@prec: 0.8082 - val_loss: 1.4325 - val_f1: 0.6101 - val_rec@prec: 0.3454\n",
            "Epoch 11/20\n",
            "43/43 [==============================] - 3s 71ms/step - loss: 0.5559 - f1: 0.8357 - rec@prec: 0.8725 - val_loss: 1.4495 - val_f1: 0.6133 - val_rec@prec: 0.3900\n",
            "Epoch 12/20\n",
            "43/43 [==============================] - 3s 74ms/step - loss: 0.4650 - f1: 0.8710 - rec@prec: 0.9107 - val_loss: 1.5221 - val_f1: 0.6212 - val_rec@prec: 0.3769\n",
            "Epoch 13/20\n",
            "43/43 [==============================] - 3s 64ms/step - loss: 0.3913 - f1: 0.8954 - rec@prec: 0.9345 - val_loss: 1.5673 - val_f1: 0.6311 - val_rec@prec: 0.4004\n",
            "Epoch 14/20\n",
            "43/43 [==============================] - 2s 47ms/step - loss: 0.3362 - f1: 0.9119 - rec@prec: 0.9512 - val_loss: 1.6661 - val_f1: 0.6331 - val_rec@prec: 0.3778\n",
            "Epoch 15/20\n",
            "43/43 [==============================] - 2s 54ms/step - loss: 0.2904 - f1: 0.9256 - rec@prec: 0.9625 - val_loss: 1.6676 - val_f1: 0.6269 - val_rec@prec: 0.4581\n",
            "Epoch 16/20\n",
            "43/43 [==============================] - 2s 54ms/step - loss: 0.2426 - f1: 0.9404 - rec@prec: 0.9730 - val_loss: 1.7204 - val_f1: 0.6278 - val_rec@prec: 0.4364\n",
            "Epoch 17/20\n",
            "43/43 [==============================] - 2s 47ms/step - loss: 0.2046 - f1: 0.9507 - rec@prec: 0.9799 - val_loss: 1.7755 - val_f1: 0.6294 - val_rec@prec: 0.4247\n",
            "Epoch 18/20\n",
            "43/43 [==============================] - 2s 50ms/step - loss: 0.1708 - f1: 0.9609 - rec@prec: 0.9857 - val_loss: 1.8316 - val_f1: 0.6313 - val_rec@prec: 0.4396\n",
            "Epoch 19/20\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.1491 - f1: 0.9661 - rec@prec: 0.9885 - val_loss: 1.9350 - val_f1: 0.6174 - val_rec@prec: 0.3927\n",
            "Epoch 20/20\n",
            "43/43 [==============================] - 2s 56ms/step - loss: 0.1306 - f1: 0.9716 - rec@prec: 0.9907 - val_loss: 1.9746 - val_f1: 0.6272 - val_rec@prec: 0.4369\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f313b61d780>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1.fit(X_train, y_train,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "         epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "G-NfLssr7bfx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-NfLssr7bfx",
        "outputId": "95d68c77-d213-4e8d-ae34-93d01598bb8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 220)]             0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 220, 60)           1445580   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 90)                54360     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 19)                1729      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1501669 (5.73 MB)\n",
            "Trainable params: 1501669 (5.73 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 2) модель с 1 LSTM слоем\n",
        "\n",
        "inputs_2 = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings_2 = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=60)(inputs_2, )\n",
        "\n",
        "rnn_2 = tf.keras.layers.LSTM(units=90, return_sequences=False)(embeddings_2)\n",
        "\n",
        "outputs_2 = tf.keras.layers.Dense(len(label2id), activation='softmax')(rnn_2)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs=inputs_2, outputs=outputs_2)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_2.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1,\n",
        "                       tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])\n",
        "\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "SwwzhPQo7bXl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwwzhPQo7bXl",
        "outputId": "bae92bcf-3d9a-40ec-a639-e8355d658bcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "43/43 [==============================] - 7s 121ms/step - loss: 2.4958 - f1: 0.0000e+00 - rec@prec: 0.0000e+00 - val_loss: 2.3182 - val_f1: 0.0000e+00 - val_rec@prec: 0.0000e+00\n",
            "Epoch 2/20\n",
            "43/43 [==============================] - 4s 98ms/step - loss: 2.3050 - f1: 0.0000e+00 - rec@prec: 0.0000e+00 - val_loss: 2.2725 - val_f1: 0.0000e+00 - val_rec@prec: 0.0027\n",
            "Epoch 3/20\n",
            "43/43 [==============================] - 4s 85ms/step - loss: 2.1936 - f1: 9.2930e-05 - rec@prec: 0.0023 - val_loss: 2.1290 - val_f1: 0.0000e+00 - val_rec@prec: 0.0014\n",
            "Epoch 4/20\n",
            "43/43 [==============================] - 4s 88ms/step - loss: 1.9471 - f1: 0.0753 - rec@prec: 0.0544 - val_loss: 1.8604 - val_f1: 0.2195 - val_rec@prec: 0.1060\n",
            "Epoch 5/20\n",
            "43/43 [==============================] - 4s 92ms/step - loss: 1.5570 - f1: 0.3773 - rec@prec: 0.2025 - val_loss: 1.6277 - val_f1: 0.4365 - val_rec@prec: 0.1438\n",
            "Epoch 6/20\n",
            "43/43 [==============================] - 3s 80ms/step - loss: 1.3290 - f1: 0.5692 - rec@prec: 0.3734 - val_loss: 1.3858 - val_f1: 0.5656 - val_rec@prec: 0.3381\n",
            "Epoch 7/20\n",
            "43/43 [==============================] - 3s 75ms/step - loss: 1.1799 - f1: 0.6395 - rec@prec: 0.4957 - val_loss: 1.3910 - val_f1: 0.5744 - val_rec@prec: 0.2498\n",
            "Epoch 8/20\n",
            "43/43 [==============================] - 3s 79ms/step - loss: 1.0883 - f1: 0.6641 - rec@prec: 0.5529 - val_loss: 1.2638 - val_f1: 0.5981 - val_rec@prec: 0.4513\n",
            "Epoch 9/20\n",
            "43/43 [==============================] - 3s 77ms/step - loss: 0.9751 - f1: 0.6995 - rec@prec: 0.6328 - val_loss: 1.2436 - val_f1: 0.6323 - val_rec@prec: 0.4680\n",
            "Epoch 10/20\n",
            "43/43 [==============================] - 2s 47ms/step - loss: 0.8678 - f1: 0.7409 - rec@prec: 0.7187 - val_loss: 1.2122 - val_f1: 0.6545 - val_rec@prec: 0.4982\n",
            "Epoch 11/20\n",
            "43/43 [==============================] - 3s 61ms/step - loss: 0.7822 - f1: 0.7771 - rec@prec: 0.7807 - val_loss: 1.1604 - val_f1: 0.6882 - val_rec@prec: 0.5509\n",
            "Epoch 12/20\n",
            "43/43 [==============================] - 2s 51ms/step - loss: 0.7064 - f1: 0.8066 - rec@prec: 0.8193 - val_loss: 1.1589 - val_f1: 0.6875 - val_rec@prec: 0.5663\n",
            "Epoch 13/20\n",
            "43/43 [==============================] - 1s 34ms/step - loss: 0.6169 - f1: 0.8375 - rec@prec: 0.8588 - val_loss: 1.3321 - val_f1: 0.6431 - val_rec@prec: 0.4802\n",
            "Epoch 14/20\n",
            "43/43 [==============================] - 2s 42ms/step - loss: 0.6487 - f1: 0.8196 - rec@prec: 0.8389 - val_loss: 1.1311 - val_f1: 0.7047 - val_rec@prec: 0.6001\n",
            "Epoch 15/20\n",
            "43/43 [==============================] - 3s 60ms/step - loss: 0.5069 - f1: 0.8712 - rec@prec: 0.9005 - val_loss: 1.1487 - val_f1: 0.7036 - val_rec@prec: 0.5938\n",
            "Epoch 16/20\n",
            "43/43 [==============================] - 2s 57ms/step - loss: 0.4439 - f1: 0.8876 - rec@prec: 0.9183 - val_loss: 1.1831 - val_f1: 0.7015 - val_rec@prec: 0.5906\n",
            "Epoch 17/20\n",
            "43/43 [==============================] - 2s 54ms/step - loss: 0.3958 - f1: 0.9017 - rec@prec: 0.9344 - val_loss: 1.2187 - val_f1: 0.6948 - val_rec@prec: 0.5839\n",
            "Epoch 18/20\n",
            "43/43 [==============================] - 2s 36ms/step - loss: 0.3633 - f1: 0.9099 - rec@prec: 0.9441 - val_loss: 1.2766 - val_f1: 0.6814 - val_rec@prec: 0.5546\n",
            "Epoch 19/20\n",
            "43/43 [==============================] - 2s 50ms/step - loss: 0.3294 - f1: 0.9201 - rec@prec: 0.9527 - val_loss: 1.3023 - val_f1: 0.7045 - val_rec@prec: 0.6082\n",
            "Epoch 20/20\n",
            "43/43 [==============================] - 2s 51ms/step - loss: 0.2907 - f1: 0.9301 - rec@prec: 0.9617 - val_loss: 1.3087 - val_f1: 0.6900 - val_rec@prec: 0.5730\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f310ffb2470>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2.fit(X_train, y_train,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "         epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "faCkGBVU7xnq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faCkGBVU7xnq",
        "outputId": "c684b6ea-008f-4fd2-c910-e67767cae3a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 220)]             0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 220, 60)           1445580   \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 220, 90)           41040     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 90)                65160     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 19)                1729      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1553509 (5.93 MB)\n",
            "Trainable params: 1553509 (5.93 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 3) модель с 1 GRU и 1 LSTM слоем\n",
        "\n",
        "inputs_3 = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings_3 = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=60)(inputs_3, )\n",
        "\n",
        "rnn_3_gru = tf.keras.layers.GRU(units=90, return_sequences=True)(embeddings_3)\n",
        "\n",
        "rnn_3_lstm = tf.keras.layers.LSTM(units=90, return_sequences=False)(rnn_3_gru)\n",
        "\n",
        "outputs_3 = tf.keras.layers.Dense(len(label2id), activation='softmax')(rnn_3_lstm)\n",
        "\n",
        "model_3 = tf.keras.Model(inputs=inputs_3, outputs=outputs_3)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_3.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1,\n",
        "                       tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])\n",
        "\n",
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "Ome2zyio9U3E",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ome2zyio9U3E",
        "outputId": "19bb5569-97cd-42d5-f970-1a66e0e3d048"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "43/43 [==============================] - 10s 163ms/step - loss: 2.4838 - f1: 0.0000e+00 - rec@prec: 0.0000e+00 - val_loss: 2.3158 - val_f1: 0.0000e+00 - val_rec@prec: 0.0000e+00\n",
            "Epoch 2/20\n",
            "43/43 [==============================] - 6s 129ms/step - loss: 2.1299 - f1: 0.0017 - rec@prec: 0.0000e+00 - val_loss: 1.8918 - val_f1: 0.0000e+00 - val_rec@prec: 0.0000e+00\n",
            "Epoch 3/20\n",
            "43/43 [==============================] - 5s 111ms/step - loss: 1.7478 - f1: 0.0965 - rec@prec: 0.0433 - val_loss: 1.7020 - val_f1: 0.2895 - val_rec@prec: 0.0920\n",
            "Epoch 4/20\n",
            "43/43 [==============================] - 5s 128ms/step - loss: 1.5765 - f1: 0.2820 - rec@prec: 0.1123 - val_loss: 1.6437 - val_f1: 0.3376 - val_rec@prec: 0.1195\n",
            "Epoch 5/20\n",
            "43/43 [==============================] - 5s 114ms/step - loss: 1.4253 - f1: 0.3512 - rec@prec: 0.1732 - val_loss: 1.5355 - val_f1: 0.3818 - val_rec@prec: 0.1637\n",
            "Epoch 6/20\n",
            "43/43 [==============================] - 5s 118ms/step - loss: 1.2795 - f1: 0.4690 - rec@prec: 0.2317 - val_loss: 1.5382 - val_f1: 0.4387 - val_rec@prec: 0.1907\n",
            "Epoch 7/20\n",
            "43/43 [==============================] - 4s 87ms/step - loss: 1.2705 - f1: 0.4673 - rec@prec: 0.2371 - val_loss: 1.4868 - val_f1: 0.4356 - val_rec@prec: 0.2087\n",
            "Epoch 8/20\n",
            "43/43 [==============================] - 4s 97ms/step - loss: 1.1665 - f1: 0.5614 - rec@prec: 0.3302 - val_loss: 1.5684 - val_f1: 0.4382 - val_rec@prec: 0.1812\n",
            "Epoch 9/20\n",
            "43/43 [==============================] - 4s 95ms/step - loss: 1.1218 - f1: 0.5504 - rec@prec: 0.3799 - val_loss: 1.4481 - val_f1: 0.5695 - val_rec@prec: 0.2565\n",
            "Epoch 10/20\n",
            "43/43 [==============================] - 3s 76ms/step - loss: 0.9704 - f1: 0.6793 - rec@prec: 0.5814 - val_loss: 1.4457 - val_f1: 0.5451 - val_rec@prec: 0.2917\n",
            "Epoch 11/20\n",
            "43/43 [==============================] - 3s 78ms/step - loss: 0.9580 - f1: 0.6923 - rec@prec: 0.6028 - val_loss: 1.4327 - val_f1: 0.5980 - val_rec@prec: 0.3386\n",
            "Epoch 12/20\n",
            "43/43 [==============================] - 4s 83ms/step - loss: 0.8547 - f1: 0.7397 - rec@prec: 0.6999 - val_loss: 1.4613 - val_f1: 0.5859 - val_rec@prec: 0.3075\n",
            "Epoch 13/20\n",
            "43/43 [==============================] - 3s 81ms/step - loss: 0.8140 - f1: 0.7520 - rec@prec: 0.7252 - val_loss: 1.4377 - val_f1: 0.6109 - val_rec@prec: 0.3990\n",
            "Epoch 14/20\n",
            "43/43 [==============================] - 3s 75ms/step - loss: 0.7512 - f1: 0.7788 - rec@prec: 0.7735 - val_loss: 1.4859 - val_f1: 0.6013 - val_rec@prec: 0.3417\n",
            "Epoch 15/20\n",
            "43/43 [==============================] - 3s 72ms/step - loss: 0.6976 - f1: 0.8033 - rec@prec: 0.8125 - val_loss: 1.4883 - val_f1: 0.6158 - val_rec@prec: 0.3688\n",
            "Epoch 16/20\n",
            "43/43 [==============================] - 3s 78ms/step - loss: 0.6680 - f1: 0.8131 - rec@prec: 0.8241 - val_loss: 1.5042 - val_f1: 0.6190 - val_rec@prec: 0.4297\n",
            "Epoch 17/20\n",
            "43/43 [==============================] - 3s 66ms/step - loss: 0.6330 - f1: 0.8260 - rec@prec: 0.8412 - val_loss: 1.5357 - val_f1: 0.6213 - val_rec@prec: 0.3977\n",
            "Epoch 18/20\n",
            "43/43 [==============================] - 3s 68ms/step - loss: 0.6074 - f1: 0.8348 - rec@prec: 0.8518 - val_loss: 1.5607 - val_f1: 0.6175 - val_rec@prec: 0.4157\n",
            "Epoch 19/20\n",
            "43/43 [==============================] - 3s 75ms/step - loss: 0.5690 - f1: 0.8482 - rec@prec: 0.8709 - val_loss: 1.5747 - val_f1: 0.6190 - val_rec@prec: 0.4432\n",
            "Epoch 20/20\n",
            "43/43 [==============================] - 3s 67ms/step - loss: 0.5429 - f1: 0.8575 - rec@prec: 0.8818 - val_loss: 1.5939 - val_f1: 0.6119 - val_rec@prec: 0.4225\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f30a07337f0>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_3.fit(X_train, y_train,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "         epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "osxKtC89-Jfz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osxKtC89-Jfz",
        "outputId": "00e3597c-992a-485d-f86e-a56265567058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 220)]             0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 220, 60)           1445580   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 220, 180)          82080     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 220, 90)           97560     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 90)                65160     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 19)                1729      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1692109 (6.45 MB)\n",
            "Trainable params: 1692109 (6.45 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 4) модель с 1 BIGRU и 2 LSTM слоями\n",
        "\n",
        "inputs_4 = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings_4 = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=60)(inputs_4, )\n",
        "\n",
        "rnn_4_bigru = tf.keras.layers.Bidirectional(\n",
        "    tf.keras.layers.GRU(units=90, return_sequences=True)\n",
        "    )(embeddings_4)\n",
        "\n",
        "rnn_4_lstm_1 = tf.keras.layers.LSTM(units=90, return_sequences=True)(rnn_4_bigru)\n",
        "\n",
        "rnn_4_lstm_2 = tf.keras.layers.LSTM(units=90, return_sequences=False)(rnn_4_lstm_1)\n",
        "\n",
        "outputs_4 = tf.keras.layers.Dense(len(label2id), activation='softmax')(rnn_4_lstm_2)\n",
        "\n",
        "model_4 = tf.keras.Model(inputs=inputs_4, outputs=outputs_4)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_4.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1,\n",
        "                       tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])\n",
        "\n",
        "model_4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "TBRy7YRD-JYB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBRy7YRD-JYB",
        "outputId": "b9c6c6f7-4174-4438-efc9-e815ba633c28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "43/43 [==============================] - 15s 228ms/step - loss: 2.4445 - f1: 0.0000e+00 - rec@prec: 0.0000e+00 - val_loss: 2.3208 - val_f1: 0.0000e+00 - val_rec@prec: 0.0000e+00\n",
            "Epoch 2/20\n",
            "43/43 [==============================] - 8s 189ms/step - loss: 2.2984 - f1: 0.0000e+00 - rec@prec: 1.8985e-04 - val_loss: 2.2640 - val_f1: 0.0000e+00 - val_rec@prec: 0.0000e+00\n",
            "Epoch 3/20\n",
            "43/43 [==============================] - 7s 174ms/step - loss: 1.9811 - f1: 0.0518 - rec@prec: 0.0254 - val_loss: 1.9110 - val_f1: 0.0746 - val_rec@prec: 0.0397\n",
            "Epoch 4/20\n",
            "43/43 [==============================] - 7s 167ms/step - loss: 1.7366 - f1: 0.1489 - rec@prec: 0.0854 - val_loss: 1.7238 - val_f1: 0.1941 - val_rec@prec: 0.1159\n",
            "Epoch 5/20\n",
            "43/43 [==============================] - 7s 169ms/step - loss: 1.6179 - f1: 0.2507 - rec@prec: 0.1200 - val_loss: 1.6620 - val_f1: 0.2397 - val_rec@prec: 0.1402\n",
            "Epoch 6/20\n",
            "43/43 [==============================] - 7s 162ms/step - loss: 1.4602 - f1: 0.3398 - rec@prec: 0.1805 - val_loss: 1.5065 - val_f1: 0.4103 - val_rec@prec: 0.1641\n",
            "Epoch 7/20\n",
            "43/43 [==============================] - 6s 149ms/step - loss: 1.3152 - f1: 0.4628 - rec@prec: 0.2503 - val_loss: 1.4891 - val_f1: 0.4192 - val_rec@prec: 0.2281\n",
            "Epoch 8/20\n",
            "43/43 [==============================] - 6s 138ms/step - loss: 1.2227 - f1: 0.5070 - rec@prec: 0.3323 - val_loss: 1.3832 - val_f1: 0.5191 - val_rec@prec: 0.3057\n",
            "Epoch 9/20\n",
            "43/43 [==============================] - 6s 138ms/step - loss: 1.1050 - f1: 0.6209 - rec@prec: 0.4855 - val_loss: 1.3503 - val_f1: 0.5854 - val_rec@prec: 0.3986\n",
            "Epoch 10/20\n",
            "43/43 [==============================] - 6s 145ms/step - loss: 0.9775 - f1: 0.6945 - rec@prec: 0.6172 - val_loss: 1.3420 - val_f1: 0.6075 - val_rec@prec: 0.4454\n",
            "Epoch 11/20\n",
            "43/43 [==============================] - 6s 140ms/step - loss: 0.8943 - f1: 0.7262 - rec@prec: 0.6824 - val_loss: 1.3193 - val_f1: 0.6166 - val_rec@prec: 0.4698\n",
            "Epoch 12/20\n",
            "43/43 [==============================] - 6s 137ms/step - loss: 0.8175 - f1: 0.7592 - rec@prec: 0.7357 - val_loss: 1.3465 - val_f1: 0.6186 - val_rec@prec: 0.4653\n",
            "Epoch 13/20\n",
            "43/43 [==============================] - 6s 135ms/step - loss: 0.7570 - f1: 0.7814 - rec@prec: 0.7727 - val_loss: 1.3669 - val_f1: 0.6289 - val_rec@prec: 0.4748\n",
            "Epoch 14/20\n",
            "43/43 [==============================] - 6s 136ms/step - loss: 0.7122 - f1: 0.7976 - rec@prec: 0.7978 - val_loss: 1.3734 - val_f1: 0.6227 - val_rec@prec: 0.4549\n",
            "Epoch 15/20\n",
            "43/43 [==============================] - 5s 124ms/step - loss: 0.6604 - f1: 0.8149 - rec@prec: 0.8270 - val_loss: 1.3560 - val_f1: 0.6231 - val_rec@prec: 0.4707\n",
            "Epoch 16/20\n",
            "43/43 [==============================] - 5s 124ms/step - loss: 0.6024 - f1: 0.8349 - rec@prec: 0.8563 - val_loss: 1.4003 - val_f1: 0.6302 - val_rec@prec: 0.4576\n",
            "Epoch 17/20\n",
            "43/43 [==============================] - 5s 118ms/step - loss: 0.5542 - f1: 0.8505 - rec@prec: 0.8755 - val_loss: 1.4094 - val_f1: 0.6385 - val_rec@prec: 0.4775\n",
            "Epoch 18/20\n",
            "43/43 [==============================] - 5s 123ms/step - loss: 0.5089 - f1: 0.8647 - rec@prec: 0.8935 - val_loss: 1.4441 - val_f1: 0.6351 - val_rec@prec: 0.4824\n",
            "Epoch 19/20\n",
            "43/43 [==============================] - 5s 128ms/step - loss: 0.4610 - f1: 0.8785 - rec@prec: 0.9108 - val_loss: 1.4498 - val_f1: 0.6544 - val_rec@prec: 0.4901\n",
            "Epoch 20/20\n",
            "43/43 [==============================] - 5s 125ms/step - loss: 0.4332 - f1: 0.8860 - rec@prec: 0.9199 - val_loss: 1.5091 - val_f1: 0.6415 - val_rec@prec: 0.4860\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f305c603040>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_4.fit(X_train, y_train,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "         epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "Rts83baT-JPx",
      "metadata": {
        "id": "Rts83baT-JPx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 220)]             0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 220, 60)           1445580   \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (None, 220, 90)           41040     \n",
            "                                                                 \n",
            " gru_4 (GRU)                 (None, 220, 90)           49140     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 220, 90)           65160     \n",
            "                                                                 \n",
            " gru_5 (GRU)                 (None, 220, 90)           49140     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 220, 90)           65160     \n",
            "                                                                 \n",
            " gru_6 (GRU)                 (None, 220, 90)           49140     \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 220, 90)           65160     \n",
            "                                                                 \n",
            " gru_7 (GRU)                 (None, 90)                49140     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 19)                1729      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1880389 (7.17 MB)\n",
            "Trainable params: 1880389 (7.17 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 5) модель с 5 GRU слоями и 3 LSTM слоями\n",
        "\n",
        "inputs_5 = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings_5 = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=60)(inputs_5, )\n",
        "\n",
        "rnn_5_gru_1 = tf.keras.layers.GRU(units=90, return_sequences=True)(embeddings_5)\n",
        "\n",
        "rnn_5_gru_2 = tf.keras.layers.GRU(units=90, return_sequences=True)(rnn_5_gru_1)\n",
        "\n",
        "rnn_5_lstm_1 = tf.keras.layers.LSTM(units=90, return_sequences=True)(rnn_5_gru_2)\n",
        "\n",
        "rnn_5_gru_3 = tf.keras.layers.GRU(units=90, return_sequences=True)(rnn_5_lstm_1)\n",
        "\n",
        "rnn_5_lstm_2 = tf.keras.layers.LSTM(units=90, return_sequences=True)(rnn_5_gru_3)\n",
        "\n",
        "rnn_5_gru_4 = tf.keras.layers.GRU(units=90, return_sequences=True)(rnn_5_lstm_2)\n",
        "\n",
        "rnn_5_lstm_3 = tf.keras.layers.LSTM(units=90, return_sequences=True)(rnn_5_gru_4)\n",
        "\n",
        "rnn_5_gru_5 = tf.keras.layers.GRU(units=90, return_sequences=False)(rnn_5_lstm_3)\n",
        "\n",
        "outputs_5 = tf.keras.layers.Dense(len(label2id), activation='softmax')(rnn_5_gru_5)\n",
        "\n",
        "model_5 = tf.keras.Model(inputs=inputs_5, outputs=outputs_5)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_5.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1,\n",
        "                       tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])\n",
        "\n",
        "model_5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "Lvy0HxuzqES5",
      "metadata": {
        "id": "Lvy0HxuzqES5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 26s 338ms/step - loss: 2.4224 - f1: 0.0000e+00 - rec@prec: 0.0000e+00 - val_loss: 2.3231 - val_f1: 0.0000e+00 - val_rec@prec: 0.0000e+00\n",
            "Epoch 2/20\n",
            "43/43 [==============================] - 12s 271ms/step - loss: 2.3237 - f1: 0.0000e+00 - rec@prec: 0.0000e+00 - val_loss: 2.3211 - val_f1: 0.0000e+00 - val_rec@prec: 0.0000e+00\n",
            "Epoch 3/20\n",
            "43/43 [==============================] - 11s 261ms/step - loss: 2.3249 - f1: 0.0000e+00 - rec@prec: 0.0000e+00 - val_loss: 2.3212 - val_f1: 0.0000e+00 - val_rec@prec: 0.0000e+00\n",
            "Epoch 4/20\n",
            "43/43 [==============================] - 11s 252ms/step - loss: 2.3232 - f1: 0.0000e+00 - rec@prec: 0.0000e+00 - val_loss: 2.3200 - val_f1: 0.0000e+00 - val_rec@prec: 0.0000e+00\n",
            "Epoch 5/20\n",
            "43/43 [==============================] - 11s 262ms/step - loss: 2.3240 - f1: 0.0000e+00 - rec@prec: 0.0000e+00 - val_loss: 2.3205 - val_f1: 0.0000e+00 - val_rec@prec: 0.0000e+00\n",
            "Epoch 6/20\n",
            "43/43 [==============================] - 11s 248ms/step - loss: 2.3219 - f1: 0.0000e+00 - rec@prec: 0.0000e+00 - val_loss: 2.3028 - val_f1: 0.0000e+00 - val_rec@prec: 0.0000e+00\n",
            "Epoch 7/20\n",
            "43/43 [==============================] - 11s 250ms/step - loss: 2.1777 - f1: 0.0000e+00 - rec@prec: 0.0000e+00 - val_loss: 1.9927 - val_f1: 0.0000e+00 - val_rec@prec: 0.0000e+00\n",
            "Epoch 8/20\n",
            "43/43 [==============================] - 11s 253ms/step - loss: 1.9072 - f1: 0.0625 - rec@prec: 1.8985e-04 - val_loss: 1.8826 - val_f1: 0.0522 - val_rec@prec: 0.0302\n",
            "Epoch 9/20\n",
            "43/43 [==============================] - 11s 251ms/step - loss: 1.6909 - f1: 0.1610 - rec@prec: 0.0616 - val_loss: 1.6921 - val_f1: 0.2013 - val_rec@prec: 0.1019\n",
            "Epoch 10/20\n",
            "43/43 [==============================] - 10s 236ms/step - loss: 1.5531 - f1: 0.2639 - rec@prec: 0.1230 - val_loss: 1.6053 - val_f1: 0.3087 - val_rec@prec: 0.1258\n",
            "Epoch 11/20\n",
            "43/43 [==============================] - 10s 238ms/step - loss: 1.4281 - f1: 0.3209 - rec@prec: 0.1632 - val_loss: 1.5963 - val_f1: 0.3023 - val_rec@prec: 0.1348\n",
            "Epoch 12/20\n",
            "43/43 [==============================] - 10s 238ms/step - loss: 1.3199 - f1: 0.4103 - rec@prec: 0.2189 - val_loss: 1.5615 - val_f1: 0.4202 - val_rec@prec: 0.1767\n",
            "Epoch 13/20\n",
            "43/43 [==============================] - 10s 240ms/step - loss: 1.2061 - f1: 0.4772 - rec@prec: 0.2727 - val_loss: 1.3866 - val_f1: 0.4678 - val_rec@prec: 0.2313\n",
            "Epoch 14/20\n",
            "43/43 [==============================] - 10s 229ms/step - loss: 1.1451 - f1: 0.5528 - rec@prec: 0.3307 - val_loss: 1.5427 - val_f1: 0.4633 - val_rec@prec: 0.1948\n",
            "Epoch 15/20\n",
            "43/43 [==============================] - 10s 242ms/step - loss: 1.1449 - f1: 0.5714 - rec@prec: 0.3549 - val_loss: 1.3570 - val_f1: 0.5544 - val_rec@prec: 0.3458\n",
            "Epoch 16/20\n",
            "43/43 [==============================] - 11s 246ms/step - loss: 0.9072 - f1: 0.7041 - rec@prec: 0.6264 - val_loss: 1.3381 - val_f1: 0.5953 - val_rec@prec: 0.3968\n",
            "Epoch 17/20\n",
            "43/43 [==============================] - 10s 227ms/step - loss: 0.7983 - f1: 0.7510 - rec@prec: 0.7215 - val_loss: 1.2727 - val_f1: 0.6432 - val_rec@prec: 0.4689\n",
            "Epoch 18/20\n",
            "43/43 [==============================] - 10s 230ms/step - loss: 0.7162 - f1: 0.7834 - rec@prec: 0.7774 - val_loss: 1.3296 - val_f1: 0.6193 - val_rec@prec: 0.4351\n",
            "Epoch 19/20\n",
            "43/43 [==============================] - 10s 244ms/step - loss: 0.6599 - f1: 0.8042 - rec@prec: 0.8147 - val_loss: 1.3433 - val_f1: 0.6366 - val_rec@prec: 0.4563\n",
            "Epoch 20/20\n",
            "43/43 [==============================] - 10s 235ms/step - loss: 0.6032 - f1: 0.8250 - rec@prec: 0.8431 - val_loss: 1.4447 - val_f1: 0.6066 - val_rec@prec: 0.4351\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f3054191360>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_5.fit(X_train, y_train,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "         epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "dDFPxSnlqF8j",
      "metadata": {
        "id": "dDFPxSnlqF8j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 220)]             0         \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 220, 60)           1445580   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 220, 170)          75120     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 220, 150)          147800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " gru_10 (GRU)                (None, 70)                46620     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 19)                1349      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1716469 (6.55 MB)\n",
            "Trainable params: 1716469 (6.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 6) модель 1 BIGRU и 1 BILSTM слоями, причем так чтобы модели для forward и backward прохода отличалис\n",
        "\n",
        "inputs_6 = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings_6 = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=60)(inputs_6, )\n",
        "\n",
        "forward_1 = tf.keras.layers.GRU(units=90, return_sequences=True)\n",
        "backward_1 = tf.keras.layers.GRU(units=80, return_sequences=True, go_backwards=True)\n",
        "rnn_6_bigru = tf.keras.layers.Bidirectional(forward_1, backward_layer=backward_1)(embeddings_6)\n",
        "\n",
        "forward_2 = tf.keras.layers.LSTM(units=80, return_sequences=True)\n",
        "backward_2 = tf.keras.layers.LSTM(units=70, return_sequences=True, go_backwards=True)\n",
        "rnn_6_bilstm = tf.keras.layers.Bidirectional(forward_2, backward_layer=backward_2)(rnn_6_bigru)\n",
        "\n",
        "rnn_6_gru = tf.keras.layers.GRU(units=70, return_sequences=False)(rnn_6_bilstm)\n",
        "\n",
        "outputs_6 = tf.keras.layers.Dense(len(label2id), activation='softmax')(rnn_6_gru)\n",
        "\n",
        "model_6 = tf.keras.Model(inputs=inputs_6, outputs=outputs_6)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_6.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1,\n",
        "                       tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])\n",
        "\n",
        "model_6.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "37-mERJrqa7o",
      "metadata": {
        "id": "37-mERJrqa7o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "43/43 [==============================] - 19s 239ms/step - loss: 2.4574 - f1: 0.0000e+00 - rec@prec: 0.0000e+00 - val_loss: 2.3006 - val_f1: 0.0000e+00 - val_rec@prec: 0.0000e+00\n",
            "Epoch 2/20\n",
            "43/43 [==============================] - 8s 194ms/step - loss: 2.0783 - f1: 0.0256 - rec@prec: 0.0039 - val_loss: 1.8388 - val_f1: 0.1210 - val_rec@prec: 0.0595\n",
            "Epoch 3/20\n",
            "43/43 [==============================] - 8s 192ms/step - loss: 1.6253 - f1: 0.2372 - rec@prec: 0.1254 - val_loss: 1.5292 - val_f1: 0.2898 - val_rec@prec: 0.1713\n",
            "Epoch 4/20\n",
            "43/43 [==============================] - 8s 177ms/step - loss: 1.3188 - f1: 0.4233 - rec@prec: 0.2679 - val_loss: 1.3510 - val_f1: 0.5058 - val_rec@prec: 0.2998\n",
            "Epoch 5/20\n",
            "43/43 [==============================] - 7s 170ms/step - loss: 1.0053 - f1: 0.6699 - rec@prec: 0.5826 - val_loss: 1.1909 - val_f1: 0.6505 - val_rec@prec: 0.5122\n",
            "Epoch 6/20\n",
            "43/43 [==============================] - 7s 166ms/step - loss: 0.7569 - f1: 0.7798 - rec@prec: 0.7726 - val_loss: 1.1700 - val_f1: 0.6788 - val_rec@prec: 0.5500\n",
            "Epoch 7/20\n",
            "43/43 [==============================] - 7s 157ms/step - loss: 0.6160 - f1: 0.8269 - rec@prec: 0.8479 - val_loss: 1.2673 - val_f1: 0.6613 - val_rec@prec: 0.5171\n",
            "Epoch 8/20\n",
            "43/43 [==============================] - 7s 162ms/step - loss: 0.5201 - f1: 0.8582 - rec@prec: 0.8854 - val_loss: 1.2449 - val_f1: 0.6918 - val_rec@prec: 0.5469\n",
            "Epoch 9/20\n",
            "43/43 [==============================] - 7s 162ms/step - loss: 0.4383 - f1: 0.8821 - rec@prec: 0.9173 - val_loss: 1.3296 - val_f1: 0.6820 - val_rec@prec: 0.5216\n",
            "Epoch 10/20\n",
            "43/43 [==============================] - 6s 151ms/step - loss: 0.3891 - f1: 0.8953 - rec@prec: 0.9321 - val_loss: 1.4206 - val_f1: 0.6751 - val_rec@prec: 0.4964\n",
            "Epoch 11/20\n",
            "43/43 [==============================] - 6s 144ms/step - loss: 0.3393 - f1: 0.9099 - rec@prec: 0.9481 - val_loss: 1.4282 - val_f1: 0.6807 - val_rec@prec: 0.5271\n",
            "Epoch 12/20\n",
            "43/43 [==============================] - 6s 146ms/step - loss: 0.3020 - f1: 0.9207 - rec@prec: 0.9575 - val_loss: 1.5440 - val_f1: 0.6689 - val_rec@prec: 0.4914\n",
            "Epoch 13/20\n",
            "43/43 [==============================] - 6s 148ms/step - loss: 0.2645 - f1: 0.9316 - rec@prec: 0.9661 - val_loss: 1.5504 - val_f1: 0.6782 - val_rec@prec: 0.5158\n",
            "Epoch 14/20\n",
            "43/43 [==============================] - 6s 150ms/step - loss: 0.2357 - f1: 0.9401 - rec@prec: 0.9728 - val_loss: 1.6442 - val_f1: 0.6714 - val_rec@prec: 0.5203\n",
            "Epoch 15/20\n",
            "43/43 [==============================] - 6s 142ms/step - loss: 0.2121 - f1: 0.9473 - rec@prec: 0.9765 - val_loss: 1.6339 - val_f1: 0.6839 - val_rec@prec: 0.5383\n",
            "Epoch 16/20\n",
            "43/43 [==============================] - 6s 142ms/step - loss: 0.1979 - f1: 0.9506 - rec@prec: 0.9794 - val_loss: 1.7245 - val_f1: 0.6770 - val_rec@prec: 0.5600\n",
            "Epoch 17/20\n",
            "43/43 [==============================] - 6s 144ms/step - loss: 0.1773 - f1: 0.9564 - rec@prec: 0.9828 - val_loss: 1.7163 - val_f1: 0.6764 - val_rec@prec: 0.5370\n",
            "Epoch 18/20\n",
            "43/43 [==============================] - 6s 138ms/step - loss: 0.1611 - f1: 0.9613 - rec@prec: 0.9849 - val_loss: 1.7401 - val_f1: 0.6759 - val_rec@prec: 0.5334\n",
            "Epoch 19/20\n",
            "43/43 [==============================] - 6s 147ms/step - loss: 0.1456 - f1: 0.9660 - rec@prec: 0.9876 - val_loss: 1.8014 - val_f1: 0.6757 - val_rec@prec: 0.5320\n",
            "Epoch 20/20\n",
            "43/43 [==============================] - 6s 134ms/step - loss: 0.1462 - f1: 0.9649 - rec@prec: 0.9877 - val_loss: 1.7999 - val_f1: 0.6752 - val_rec@prec: 0.5293\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f2ff06f76a0>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_6.fit(X_train, y_train,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "         epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "784be536",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 220)]             0         \n",
            "                                                                 \n",
            " embedding_6 (Embedding)     (None, 220, 60)           1445580   \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 220, 90)           54360     \n",
            "                                                                 \n",
            " gru_11 (GRU)                (None, 220, 90)           49140     \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 220, 170)          119880    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirecti  (None, 220, 150)          111300    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " gru_14 (GRU)                (None, 220, 90)           65340     \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 90)                65160     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 19)                1729      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1912489 (7.30 MB)\n",
            "Trainable params: 1912489 (7.30 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 7) модель, где последовательно идут слои: LSTM, GRU, BILSTM, BIGRU, GRU, LSTM\n",
        "\n",
        "inputs_7 = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings_7 = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=60)(inputs_7, )\n",
        "\n",
        "rnn_7_lstm_1 = tf.keras.layers.LSTM(units=90, return_sequences=True)(embeddings_7)\n",
        "\n",
        "rnn_7_gru_1 = tf.keras.layers.GRU(units=90, return_sequences=True)(rnn_7_lstm_1)\n",
        "\n",
        "forward_1 = tf.keras.layers.LSTM(units=90, return_sequences=True)\n",
        "backward_1 = tf.keras.layers.LSTM(units=80, return_sequences=True, go_backwards=True)\n",
        "rnn_7_bilstm = tf.keras.layers.Bidirectional(forward_1, backward_layer=backward_1)(rnn_7_gru_1)\n",
        "\n",
        "forward_2 = tf.keras.layers.GRU(units=80, return_sequences=True)\n",
        "backward_2 = tf.keras.layers.GRU(units=70, return_sequences=True, go_backwards=True)\n",
        "rnn_7_bigru = tf.keras.layers.Bidirectional(forward_2, backward_layer=backward_2)(rnn_7_bilstm)\n",
        "\n",
        "rnn_7_gru_2 = tf.keras.layers.GRU(units=90, return_sequences=True)(rnn_7_bigru)\n",
        "\n",
        "rnn_7_lstm_2 = tf.keras.layers.LSTM(units=90, return_sequences=False)(rnn_7_gru_2)\n",
        "\n",
        "outputs_7 = tf.keras.layers.Dense(len(label2id), activation='softmax')(rnn_7_lstm_2)\n",
        "\n",
        "model_7 = tf.keras.Model(inputs=inputs_7, outputs=outputs_7)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_7.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1,\n",
        "                       tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])\n",
        "\n",
        "model_7.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "3854d8fd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "43/43 [==============================] - 25s 329ms/step - loss: 2.4272 - f1: 0.0000e+00 - rec@prec: 0.0000e+00 - val_loss: 2.3219 - val_f1: 0.0000e+00 - val_rec@prec: 0.0000e+00\n",
            "Epoch 2/20\n",
            "43/43 [==============================] - 11s 262ms/step - loss: 2.2341 - f1: 0.0010 - rec@prec: 0.0047 - val_loss: 2.1146 - val_f1: 0.0666 - val_rec@prec: 0.0464\n",
            "Epoch 3/20\n",
            "43/43 [==============================] - 11s 267ms/step - loss: 1.8215 - f1: 0.1723 - rec@prec: 0.0782 - val_loss: 1.7734 - val_f1: 0.1786 - val_rec@prec: 0.0983\n",
            "Epoch 4/20\n",
            "43/43 [==============================] - 10s 244ms/step - loss: 1.6053 - f1: 0.3478 - rec@prec: 0.1522 - val_loss: 1.6949 - val_f1: 0.3595 - val_rec@prec: 0.1637\n",
            "Epoch 5/20\n",
            "43/43 [==============================] - 11s 249ms/step - loss: 1.4866 - f1: 0.4272 - rec@prec: 0.2520 - val_loss: 1.5885 - val_f1: 0.4214 - val_rec@prec: 0.2480\n",
            "Epoch 6/20\n",
            "43/43 [==============================] - 10s 243ms/step - loss: 1.3078 - f1: 0.5187 - rec@prec: 0.3528 - val_loss: 1.4866 - val_f1: 0.4972 - val_rec@prec: 0.2367\n",
            "Epoch 7/20\n",
            "43/43 [==============================] - 11s 248ms/step - loss: 1.1243 - f1: 0.6278 - rec@prec: 0.4846 - val_loss: 1.4649 - val_f1: 0.5593 - val_rec@prec: 0.3021\n",
            "Epoch 8/20\n",
            "43/43 [==============================] - 10s 242ms/step - loss: 0.9722 - f1: 0.7038 - rec@prec: 0.6253 - val_loss: 1.3065 - val_f1: 0.6125 - val_rec@prec: 0.3589\n",
            "Epoch 9/20\n",
            "43/43 [==============================] - 11s 245ms/step - loss: 0.8185 - f1: 0.7648 - rec@prec: 0.7423 - val_loss: 1.2733 - val_f1: 0.6375 - val_rec@prec: 0.4549\n",
            "Epoch 10/20\n",
            "43/43 [==============================] - 10s 242ms/step - loss: 0.7241 - f1: 0.8007 - rec@prec: 0.8032 - val_loss: 1.2928 - val_f1: 0.6499 - val_rec@prec: 0.4851\n",
            "Epoch 11/20\n",
            "43/43 [==============================] - 10s 230ms/step - loss: 0.6422 - f1: 0.8282 - rec@prec: 0.8454 - val_loss: 1.3052 - val_f1: 0.6539 - val_rec@prec: 0.4833\n",
            "Epoch 12/20\n",
            "43/43 [==============================] - 10s 223ms/step - loss: 0.5893 - f1: 0.8439 - rec@prec: 0.8666 - val_loss: 1.3248 - val_f1: 0.6487 - val_rec@prec: 0.4793\n",
            "Epoch 13/20\n",
            "43/43 [==============================] - 10s 233ms/step - loss: 0.5297 - f1: 0.8628 - rec@prec: 0.8890 - val_loss: 1.3455 - val_f1: 0.6493 - val_rec@prec: 0.4887\n",
            "Epoch 14/20\n",
            "43/43 [==============================] - 10s 223ms/step - loss: 0.4830 - f1: 0.8783 - rec@prec: 0.9055 - val_loss: 1.4098 - val_f1: 0.6475 - val_rec@prec: 0.4833\n",
            "Epoch 15/20\n",
            "43/43 [==============================] - 10s 227ms/step - loss: 0.4368 - f1: 0.8895 - rec@prec: 0.9203 - val_loss: 1.4511 - val_f1: 0.6436 - val_rec@prec: 0.4337\n",
            "Epoch 16/20\n",
            "43/43 [==============================] - 10s 224ms/step - loss: 0.4112 - f1: 0.8959 - rec@prec: 0.9274 - val_loss: 1.5151 - val_f1: 0.6264 - val_rec@prec: 0.3805\n",
            "Epoch 17/20\n",
            "43/43 [==============================] - 10s 231ms/step - loss: 0.3998 - f1: 0.8997 - rec@prec: 0.9311 - val_loss: 1.4919 - val_f1: 0.6277 - val_rec@prec: 0.4779\n",
            "Epoch 18/20\n",
            "43/43 [==============================] - 10s 221ms/step - loss: 0.3681 - f1: 0.9074 - rec@prec: 0.9401 - val_loss: 1.5319 - val_f1: 0.6311 - val_rec@prec: 0.4315\n",
            "Epoch 19/20\n",
            "43/43 [==============================] - 10s 222ms/step - loss: 0.3369 - f1: 0.9157 - rec@prec: 0.9484 - val_loss: 1.5530 - val_f1: 0.6430 - val_rec@prec: 0.3688\n",
            "Epoch 20/20\n",
            "43/43 [==============================] - 10s 235ms/step - loss: 0.3105 - f1: 0.9229 - rec@prec: 0.9548 - val_loss: 1.5778 - val_f1: 0.6411 - val_rec@prec: 0.4076\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f30217a7760>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_7.fit(X_train, y_train,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "         epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "160e11ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "models = [\n",
        "    model_1,\n",
        "    model_2,\n",
        "    model_3,\n",
        "    model_4,\n",
        "    model_5,\n",
        "    model_6,\n",
        "    model_7\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "551eef56",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Модель №1, F1 - 0.6271504759788513\n",
            "Модель №2, F1 - 0.6899943351745605\n",
            "Модель №3, F1 - 0.6119385361671448\n",
            "Модель №4, F1 - 0.6414610743522644\n",
            "Модель №5, F1 - 0.6066408157348633\n",
            "Модель №6, F1 - 0.6752133369445801\n",
            "Модель №7, F1 - 0.6411024928092957\n",
            "С F1 0.6411024928092957 лучшая модель - №6\n"
          ]
        }
      ],
      "source": [
        "f1s = []\n",
        "for i, model in enumerate(models):\n",
        "    f1 = (model.get_metrics_result()['f1']).numpy()\n",
        "    f1s.append((i, f1))\n",
        "    print(f\"Модель №{i+1}, F1 - {f1}\")\n",
        "\n",
        "maxf1 = max(f1s)\n",
        "print(f\"С F1 {maxf1[1]} лучшая модель - №{maxf1[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed5d6eea",
      "metadata": {
        "id": "ed5d6eea"
      },
      "source": [
        "## Задание 2 (6 баллов)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c2c07cf",
      "metadata": {
        "id": "5c2c07cf"
      },
      "source": [
        "На данных википедии (wikiann) обучите 2 модели:  \n",
        "1) модель в которой будут использованы предобученные эмбединги слов и несколько BILSTM слоев.\n",
        "1) модель в которой будут использованы предобученные эмбединги слов и несколько BIGRU слоев.\n",
        "\n",
        "Сравните качество по метрикам. Также придумайте несколько сложных примеров и проверьте, какие сущности определяет каждая из моделей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "d12643af",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.17.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /home/user/.venv/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/user/.venv/lib/python3.10/site-packages (from datasets) (1.24.4)\n",
            "Collecting pyarrow>=12.0.0 (from datasets)\n",
            "  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /home/user/.venv/lib/python3.10/site-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /home/user/.venv/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /home/user/.venv/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /home/user/.venv/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /home/user/.venv/lib/python3.10/site-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /home/user/.venv/lib/python3.10/site-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/user/.venv/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/user/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/user/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/user/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/user/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/user/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/user/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/user/.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/user/.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/user/.venv/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/user/.venv/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/user/.venv/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/user/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow-hotfix, pyarrow, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.2.0\n",
            "    Uninstalling fsspec-2024.2.0:\n",
            "      Successfully uninstalled fsspec-2024.2.0\n",
            "Successfully installed datasets-2.17.1 dill-0.3.8 fsspec-2023.10.0 multiprocess-0.70.16 pyarrow-15.0.0 pyarrow-hotfix-0.6 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "42f22349",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/user/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "0baad42c",
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "Unable to find 'hf://datasets/wikiann@dc60b43e8e7e1c939a18bf5da8aac1b3f174cab6/ru/validation/0000.parquet' with any supported extension ['.csv', '.tsv', '.json', '.jsonl', '.parquet', '.geoparquet', '.gpq', '.arrow', '.txt', '.tar', '.blp', '.bmp', '.dib', '.bufr', '.cur', '.pcx', '.dcx', '.dds', '.ps', '.eps', '.fit', '.fits', '.fli', '.flc', '.ftc', '.ftu', '.gbr', '.gif', '.grib', '.h5', '.hdf', '.png', '.apng', '.jp2', '.j2k', '.jpc', '.jpf', '.jpx', '.j2c', '.icns', '.ico', '.im', '.iim', '.tif', '.tiff', '.jfif', '.jpe', '.jpg', '.jpeg', '.mpg', '.mpeg', '.msp', '.pcd', '.pxr', '.pbm', '.pgm', '.ppm', '.pnm', '.psd', '.bw', '.rgb', '.rgba', '.sgi', '.ras', '.tga', '.icb', '.vda', '.vst', '.webp', '.wmf', '.emf', '.xbm', '.xpm', '.BLP', '.BMP', '.DIB', '.BUFR', '.CUR', '.PCX', '.DCX', '.DDS', '.PS', '.EPS', '.FIT', '.FITS', '.FLI', '.FLC', '.FTC', '.FTU', '.GBR', '.GIF', '.GRIB', '.H5', '.HDF', '.PNG', '.APNG', '.JP2', '.J2K', '.JPC', '.JPF', '.JPX', '.J2C', '.ICNS', '.ICO', '.IM', '.IIM', '.TIF', '.TIFF', '.JFIF', '.JPE', '.JPG', '.JPEG', '.MPG', '.MPEG', '.MSP', '.PCD', '.PXR', '.PBM', '.PGM', '.PPM', '.PNM', '.PSD', '.BW', '.RGB', '.RGBA', '.SGI', '.RAS', '.TGA', '.ICB', '.VDA', '.VST', '.WEBP', '.WMF', '.EMF', '.XBM', '.XPM', '.aiff', '.au', '.avr', '.caf', '.flac', '.htk', '.svx', '.mat4', '.mat5', '.mpc2k', '.ogg', '.paf', '.pvf', '.raw', '.rf64', '.sd2', '.sds', '.ircam', '.voc', '.w64', '.wav', '.nist', '.wavex', '.wve', '.xi', '.mp3', '.opus', '.AIFF', '.AU', '.AVR', '.CAF', '.FLAC', '.HTK', '.SVX', '.MAT4', '.MAT5', '.MPC2K', '.OGG', '.PAF', '.PVF', '.RAW', '.RF64', '.SD2', '.SDS', '.IRCAM', '.VOC', '.W64', '.WAV', '.NIST', '.WAVEX', '.WVE', '.XI', '.MP3', '.OPUS', '.zip']",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwikiann\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mru\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m dataset\n",
            "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/datasets/load.py:2548\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2543\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2544\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2545\u001b[0m )\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2548\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2565\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
            "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/datasets/load.py:2257\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   2255\u001b[0m builder_cls \u001b[38;5;241m=\u001b[39m get_dataset_builder_class(dataset_module, dataset_name\u001b[38;5;241m=\u001b[39mdataset_name)\n\u001b[1;32m   2256\u001b[0m \u001b[38;5;66;03m# Instantiate the dataset builder\u001b[39;00m\n\u001b[0;32m-> 2257\u001b[0m builder_instance: DatasetBuilder \u001b[38;5;241m=\u001b[39m \u001b[43mbuilder_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mhash\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2264\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2268\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbuilder_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2269\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2270\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2271\u001b[0m builder_instance\u001b[38;5;241m.\u001b[39m_use_legacy_cache_dir_if_possible(dataset_module)\n\u001b[1;32m   2273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\n",
            "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/datasets/builder.py:371\u001b[0m, in \u001b[0;36mDatasetBuilder.__init__\u001b[0;34m(self, cache_dir, dataset_name, config_name, hash, base_path, info, features, token, use_auth_token, repo_id, data_files, data_dir, storage_options, writer_batch_size, name, **config_kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     config_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data_dir\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_builder_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# prepare info: DatasetInfo are a standardized dataclass across all datasets\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m# Prefill datasetinfo\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# TODO FOR PACKAGED MODULES IT IMPORTS DATA FROM src/packaged_modules which doesn't make sense\u001b[39;00m\n",
            "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/datasets/builder.py:620\u001b[0m, in \u001b[0;36mDatasetBuilder._create_builder_config\u001b[0;34m(self, config_name, custom_features, **config_kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilderConfig must have a name, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbuilder_config\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# resolve data files if needed\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m \u001b[43mbuilder_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_data_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDownloadConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;66;03m# compute the config id that is going to be used for caching\u001b[39;00m\n\u001b[1;32m    626\u001b[0m config_id \u001b[38;5;241m=\u001b[39m builder_config\u001b[38;5;241m.\u001b[39mcreate_config_id(\n\u001b[1;32m    627\u001b[0m     config_kwargs,\n\u001b[1;32m    628\u001b[0m     custom_features\u001b[38;5;241m=\u001b[39mcustom_features,\n\u001b[1;32m    629\u001b[0m )\n",
            "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/datasets/builder.py:211\u001b[0m, in \u001b[0;36mBuilderConfig._resolve_data_files\u001b[0;34m(self, base_path, download_config)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files, DataFilesPatternsDict):\n\u001b[1;32m    210\u001b[0m     base_path \u001b[38;5;241m=\u001b[39m xjoin(base_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir \u001b[38;5;28;01melse\u001b[39;00m base_path\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/datasets/data_files.py:792\u001b[0m, in \u001b[0;36mDataFilesPatternsDict.resolve\u001b[0;34m(self, base_path, download_config)\u001b[0m\n\u001b[1;32m    790\u001b[0m out \u001b[38;5;241m=\u001b[39m DataFilesDict()\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, data_files_patterns_list \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 792\u001b[0m     out[key] \u001b[38;5;241m=\u001b[39m \u001b[43mdata_files_patterns_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/datasets/data_files.py:745\u001b[0m, in \u001b[0;36mDataFilesPatternsList.resolve\u001b[0;34m(self, base_path, download_config)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pattern, allowed_extensions \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallowed_extensions):\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    744\u001b[0m         data_files\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 745\u001b[0m             \u001b[43mresolve_pattern\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m                \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m         )\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n",
            "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/datasets/data_files.py:386\u001b[0m, in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allowed_extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m         error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with any supported extension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(allowed_extensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(error_msg)\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Unable to find 'hf://datasets/wikiann@dc60b43e8e7e1c939a18bf5da8aac1b3f174cab6/ru/validation/0000.parquet' with any supported extension ['.csv', '.tsv', '.json', '.jsonl', '.parquet', '.geoparquet', '.gpq', '.arrow', '.txt', '.tar', '.blp', '.bmp', '.dib', '.bufr', '.cur', '.pcx', '.dcx', '.dds', '.ps', '.eps', '.fit', '.fits', '.fli', '.flc', '.ftc', '.ftu', '.gbr', '.gif', '.grib', '.h5', '.hdf', '.png', '.apng', '.jp2', '.j2k', '.jpc', '.jpf', '.jpx', '.j2c', '.icns', '.ico', '.im', '.iim', '.tif', '.tiff', '.jfif', '.jpe', '.jpg', '.jpeg', '.mpg', '.mpeg', '.msp', '.pcd', '.pxr', '.pbm', '.pgm', '.ppm', '.pnm', '.psd', '.bw', '.rgb', '.rgba', '.sgi', '.ras', '.tga', '.icb', '.vda', '.vst', '.webp', '.wmf', '.emf', '.xbm', '.xpm', '.BLP', '.BMP', '.DIB', '.BUFR', '.CUR', '.PCX', '.DCX', '.DDS', '.PS', '.EPS', '.FIT', '.FITS', '.FLI', '.FLC', '.FTC', '.FTU', '.GBR', '.GIF', '.GRIB', '.H5', '.HDF', '.PNG', '.APNG', '.JP2', '.J2K', '.JPC', '.JPF', '.JPX', '.J2C', '.ICNS', '.ICO', '.IM', '.IIM', '.TIF', '.TIFF', '.JFIF', '.JPE', '.JPG', '.JPEG', '.MPG', '.MPEG', '.MSP', '.PCD', '.PXR', '.PBM', '.PGM', '.PPM', '.PNM', '.PSD', '.BW', '.RGB', '.RGBA', '.SGI', '.RAS', '.TGA', '.ICB', '.VDA', '.VST', '.WEBP', '.WMF', '.EMF', '.XBM', '.XPM', '.aiff', '.au', '.avr', '.caf', '.flac', '.htk', '.svx', '.mat4', '.mat5', '.mpc2k', '.ogg', '.paf', '.pvf', '.raw', '.rf64', '.sd2', '.sds', '.ircam', '.voc', '.w64', '.wav', '.nist', '.wavex', '.wve', '.xi', '.mp3', '.opus', '.AIFF', '.AU', '.AVR', '.CAF', '.FLAC', '.HTK', '.SVX', '.MAT4', '.MAT5', '.MPC2K', '.OGG', '.PAF', '.PVF', '.RAW', '.RF64', '.SD2', '.SDS', '.IRCAM', '.VOC', '.W64', '.WAV', '.NIST', '.WAVEX', '.WVE', '.XI', '.MP3', '.OPUS', '.zip']"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"wikiann\", 'ru')\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "308518d5",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b12ec9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = Counter()\n",
        "\n",
        "for text in data.tokens:\n",
        "    vocab.update(preprocess(text))\n",
        "\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cc3b880",
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_vocab = set()\n",
        "\n",
        "for word in vocab:\n",
        "    if vocab[word] > 30:\n",
        "        filtered_vocab.add(word)\n",
        "\n",
        "\n",
        "len(filtered_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ab10d81",
      "metadata": {},
      "outputs": [],
      "source": [
        "word2id = {'PAD':0, 'UNK':1}\n",
        "\n",
        "for word in filtered_vocab:\n",
        "    word2id[word] = len(word2id)\n",
        "\n",
        "id2word = {i:word for word, i in word2id.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5ac9c2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "X = []\n",
        "\n",
        "for text in data.text:\n",
        "    tokens = preprocess(text)\n",
        "    ids = [word2id.get(token, 1) for token in tokens]\n",
        "    X.append(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00a491a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_LEN = max(len(x) for x in X)\n",
        "\n",
        "MEAN_LEN = np.median([len(x) for x in X])\n",
        "MAX_LEN, MEAN_LEN\n",
        "\n",
        "MAX_LEN = int(MEAN_LEN + 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04b2c813",
      "metadata": {},
      "outputs": [],
      "source": [
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_LEN)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f335783",
      "metadata": {},
      "outputs": [],
      "source": [
        "id2label = {i:label for i, label in enumerate(set(data.topic.values))}\n",
        "label2id = {l:i for i, l in id2label.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19b195b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "y = tf.keras.utils.to_categorical([label2id[label] for label in data.topic.values])\n",
        "len(label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb704b1b",
      "metadata": {
        "id": "fb704b1b"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24b4e4aa",
      "metadata": {
        "id": "24b4e4aa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8035db14",
      "metadata": {
        "id": "8035db14"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
